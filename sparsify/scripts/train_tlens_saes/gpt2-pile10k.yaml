seed: 0
tlens_model_name: gpt2-small
tlens_model_path: null
train:
  n_samples: 2000
  batch_size: 8
  effective_batch_size: 128
  lr: 1e-3
  warmup_steps: 0
  max_grad_norm: 1.0
  loss_configs:
    sparsity:
      p_norm: 0.7
      coeff: 0.001
    inp_to_orig:
      coeff: 1.0
    out_to_orig:
      coeff: 1.0
    inp_to_out: null
    logits:
      coeff: 1.0
data:
  dataset_name: NeelNanda/pile-10k
  is_tokenized: false
  tokenizer_name: gpt2
  streaming: false
  split: train
  n_ctx: 1024
  column_name: tokens
saes:
  sae_position_name: hook_resid_post
wandb_project: gpt2-small-pile10k