program: sparsify/scripts/train_tlens_saes/run_train_tlens_saes.py
name: gpt2-e2e
method: grid
metric:
  name: val_loss
  goal: minimize
parameters:
  wandb_run_name_prefix:
    values: ["seed0_"]
  seed:
    values: [0]
  n_samples:
    values: [200_000]
  lr:
    values: [1e-3]
  loss:
    parameters:
      sparsity:
        parameters:
          coeff:
            values: [0.08, 0.2, 0.8, 2]
      in_to_orig:
        values: [null]
      out_to_orig:
        values: [null]
      out_to_in:
        values: [0.0]
      logits_kl:
        parameters:
          coeff:
            values: [1.0]
  saes:
    parameters:
      sae_positions:
        values:
          - blocks.2.hook_resid_pre
      dict_size_to_input_ratio:
        values: [60.0]

  train_data:
    parameters:
      dataset_name:
        values: [apollo-research/Skylion007-openwebtext-tokenizer-gpt2]
      is_tokenized:
        values: [true]
      tokenizer_name:
        values: [gpt2]
      streaming:
        values: [true]
      split:
        values: [train]
      n_ctx:
        values: [1024]
      seed:
        values: [0]
  eval_data:
    parameters:
      dataset_name:
        values: [apollo-research/Skylion007-openwebtext-tokenizer-gpt2]
      is_tokenized:
        values: [true]
      tokenizer_name:
        values: [gpt2]
      streaming:
        values: [true]
      split:
        values: [train]
      n_ctx:
        values: [1024]
      seed:
        values: [42]
command:
- ${env}
- ${interpreter}
- ${program}
- sparsify/scripts/train_tlens_saes/gpt2.yaml