{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import TYPE_CHECKING\n",
    "if TYPE_CHECKING:\n",
    "    from transformer_lens import HookedTransformer\n",
    "\n",
    "# from IPython import get_ipython\n",
    "# ipython = get_ipython()\n",
    "# ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "# ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "from IPython.display import display, HTML\n",
    "from natsort import natsorted\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "\n",
    "from sparsify.models.transformers import SAETransformer\n",
    "from sparsify.log import logger\n",
    "from sparsify.utils import filter_names, load_config\n",
    "from sparsify.data import DataConfig\n",
    "from sparsify.loader import load_tlens_model, load_pretrained_saes\n",
    "from sparsify.scripts.train_tlens_saes.run_train_tlens_saes import Config\n",
    "from sparsify.scripts.train_tlens_saes.run_train_tlens_saes import main as run_train\n",
    "from sparsify.scripts.generate_dashboards import DashboardsConfig, PromptDashboardsConfig, generate_dashboards\n",
    "from sparsify.utils import replace_pydantic_model\n",
    "current_dir = Path(os.getcwd())\n",
    "sae_save_dir = Path(current_dir) / Path(\"run_for_testing_feature_dashboards\")\n",
    "dashboard_data_save_dir = sae_save_dir / Path(\"feature_dashboard_data\")\n",
    "sae_position_name = \"blocks.1.hook_resid_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAEs already exist in sae_save_dir = /mnt/c/Users/nadro/Documents/AI_safety/MATS5/Sparsify/sparsify/notebooks/run_for_testing_feature_dashboards\n",
      "Using those.\n"
     ]
    }
   ],
   "source": [
    "# Train a SAE on tiny-stories-1M and save it to sae_save_dir \n",
    "# Just load a pretrained SAE if we already have one handy\n",
    "if len(list(sae_save_dir.glob(\"*.pt\"))) > 0 or len(list(sae_save_dir.glob(\"*/*.pt\"))) > 0 or len(list(sae_save_dir.glob(\"*\\\\*.pt\"))) > 0: \n",
    "    print(f\"SAEs already exist in sae_save_dir = {sae_save_dir}\\nUsing those.\")\n",
    "else:\n",
    "    # Train a shitty SAE if we don't have one already\n",
    "    config_path_str = Path('../sparsify/scripts/train_tlens_saes/tinystories_1M.yaml')\n",
    "    with open(config_path_str) as f:\n",
    "        base_config = Config(**yaml.safe_load(stream=f))\n",
    "    update_dict = {\n",
    "                \"train\": {\n",
    "                    \"save_dir\": sae_save_dir,\n",
    "                    \"save_every_n_samples\": 20000,\n",
    "                    \"n_samples\": 20000,\n",
    "                    \"loss_configs\": {\n",
    "                    \"inp_to_out\":{\"coeff\":1.0},\n",
    "                    \"logits_kl\": None}},\n",
    "                \"saes\": {\"sae_position_names\": sae_position_name},\n",
    "                \"wandb_project\": None,\n",
    "            }\n",
    "    new_config = replace_pydantic_model(base_config, update_dict)\n",
    "    print(new_config)\n",
    "    run_train(new_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model and SAEs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 12:51:49 - INFO - seed=0 tlens_model_name='roneneldan/TinyStories-1M' tlens_model_path=None train=TrainConfig(save_dir=PosixPath('/mnt/c/Users/nadro/Documents/AI_safety/MATS5/Sparsify/sparsify/notebooks/run_for_testing_feature_dashboards'), save_every_n_samples=20000, n_samples=20000, batch_size=10, effective_batch_size=10, lr=0.001, warmup_samples=20000, cooldown_samples=0, max_grad_norm=1.0, log_every_n_grad_steps=20, collect_discrete_metrics_every_n_samples=10000, discrete_metrics_n_tokens=500000, collect_output_metrics_every_n_samples=0, loss_configs=LossConfigs(sparsity=SparsityLossConfig(coeff=5e-06, p_norm=0.6), inp_to_orig=None, out_to_orig=None, inp_to_out=InpToOutLossConfig(coeff=1.0), logits_kl=None)) data=DataConfig(dataset_name='apollo-research/sae-skeskinen-TinyStories-hf-tokenizer-gpt2', is_tokenized=True, tokenizer_name='gpt2', streaming=True, split='train', n_ctx=512, column_name='input_ids') saes=SparsifiersConfig(type_of_sparsifier='sae', dict_size_to_input_ratio=10.0, k=None, pretrained_sae_paths=None, retrain_saes=False, sae_position_names=['blocks.1.hook_resid_post']) wandb_project=None wandb_run_name=None wandb_run_name_prefix=''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load the saved SAEs and the corresponding model\n",
    "def load_SAETransformer_from_saes_path(\n",
    "    saes_path: Path,\n",
    "    config_path: str | Path | None = None,\n",
    "    tlens_model: HookedTransformer | None = None,\n",
    ") -> tuple[SAETransformer, Config, list[str]]:\n",
    "    saes_path = Path(saes_path)\n",
    "    # Allow passing in a directoty and finding the latest .pt or .pth file in it:\n",
    "    if saes_path.suffix != \".pt\" and saes_path.suffix != \".pth\":\n",
    "        if not saes_path.is_dir():\n",
    "            saes_path = saes_path.parent\n",
    "        saes_paths = natsorted(list(saes_path.glob(\"*.pt\")) + list(saes_path.glob(\"*.pth\")))\n",
    "        if len(saes_paths) == 0:\n",
    "            saes_paths = natsorted(list(saes_path.glob(\"*/*.pt\")) + list(saes_path.glob(\"*/*.pth\")))\n",
    "        if len(saes_paths) == 0:\n",
    "            saes_paths = natsorted(list(saes_path.glob(\"*\\\\*.pt\")) + list(saes_path.glob(\"*\\\\*.pth\")))\n",
    "        assert len(saes_paths) > 0, \"Could not find any .pt or .pth files in the saes_path\"\n",
    "        saes_path = saes_paths[-1]\n",
    "    assert saes_path.exists(), \"saes_path does not exist\"\n",
    "    config_path = saes_path.parent / \"config.yaml\" if config_path is None else Path(config_path)\n",
    "    assert (\n",
    "        config_path.exists()\n",
    "    ), \"Could not find the config_path: config.yaml should be in the same folder as the saes_path\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config = load_config(config_path, config_model=Config)\n",
    "    logger.info(config)\n",
    "    if tlens_model is None:\n",
    "        tlens_model = load_tlens_model(\n",
    "            tlens_model_name=config.tlens_model_name, tlens_model_path=config.tlens_model_path\n",
    "        )\n",
    "    raw_sae_position_names = filter_names(\n",
    "        list(tlens_model.hook_dict.keys()), config.saes.sae_position_names\n",
    "    )\n",
    "    model = SAETransformer(\n",
    "        config=config, tlens_model=tlens_model, raw_sae_position_names=raw_sae_position_names\n",
    "    ).to(device=device)\n",
    "\n",
    "    all_param_names = [name for name, _ in model.saes.named_parameters()]\n",
    "    trainable_param_names = load_pretrained_saes(\n",
    "        saes=model.saes,\n",
    "        pretrained_sae_paths=[saes_path]\n",
    "        if config.saes.pretrained_sae_paths is None\n",
    "        else [saes_path] + config.saes.pretrained_sae_paths,\n",
    "        all_param_names=all_param_names,\n",
    "        retrain_saes=config.saes.retrain_saes,\n",
    "    )\n",
    "    return model, config, trainable_param_names\n",
    "\n",
    "print(\"Loading the model and SAEs\")\n",
    "model, config, _ = load_SAETransformer_from_saes_path(sae_save_dir)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roneneldan/TinyStories-1M'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.tlens_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  7 12:51:52 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.04.01    Driver Version: 511.09       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   67C    P2    29W /  N/A |    552MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     26552      C   /python3.12                     N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    dataset_name='apollo-research/sae-skeskinen-TinyStories-hf-tokenizer-gpt2', \n",
    "    tokenizer_name='gpt2', \n",
    "    split = \"train\",\n",
    "    n_ctx=512, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for DashboardsConfig\nstore_features_as_sparse\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate the dashboards\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dashboards_config \u001b[38;5;241m=\u001b[39m \u001b[43mDashboardsConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminibatch_size_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstore_features_as_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_centric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPromptDashboardsConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSally met Mike at the show. She brought popcorn for him.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_random_prompt_dashboards\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m generate_dashboards(model, dashboards_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for DashboardsConfig\nstore_features_as_sparse\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.6/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "# Generate the dashboards\n",
    "dashboards_config = DashboardsConfig(\n",
    "    n_samples = 200, \n",
    "    batch_size = 2,\n",
    "    minibatch_size_features = 100,\n",
    "    data = data_config,\n",
    "    feature_indices = list(range(50)),\n",
    "    prompt_centric = PromptDashboardsConfig(\n",
    "        prompts = [\"Sally met Mike at the show. She brought popcorn for him.\"],\n",
    "        n_random_prompt_dashboards = 0\n",
    "    )\n",
    ")\n",
    "generate_dashboards(model, dashboards_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
